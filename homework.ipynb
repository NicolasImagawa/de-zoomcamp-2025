{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55880c09-16c3-4698-a02c-925701d9eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bdb8944-f11c-495c-9c7e-e0b04a96e6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c7f3b76-5ea8-40da-8d70-a4f0df962238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-06 12:45:48--  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-10.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 13.226.36.130, 13.226.36.73, 13.226.36.218, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|13.226.36.130|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 64346071 (61M) [binary/octet-stream]\n",
      "Saving to: ‘yellow_tripdata_2024-10.parquet’\n",
      "\n",
      "yellow_tripdata_202 100%[===================>]  61.36M  59.5MB/s    in 1.0s    \n",
      "\n",
      "2025-03-06 12:45:49 (59.5 MB/s) - ‘yellow_tripdata_2024-10.parquet’ saved [64346071/64346071]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-10.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "742e0feb-308a-4cd3-a6a0-14ec6ec7db93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/03/06 17:24:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"homework-5\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42610d55-32d2-4c61-ade8-385d31cf567c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_ingestion.ipynb  yellow_tripdata_2024-10.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30747055-a08a-47e5-b969-b299c213c468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "file_path = \"yellow_tripdata_2024-10.parquet\"\n",
    "df = spark.read.parquet(file_path).repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74c2f7d2-7217-4ce1-b0b0-875fc77a06b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "path file:/home/nicolas/notebooks/week_5/homework/rep/rep-yellow_tripdata_2024-10.parquet already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rep_output \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrep/rep-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/readwriter.py:1140\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[0;32m-> 1140\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: path file:/home/nicolas/notebooks/week_5/homework/rep/rep-yellow_tripdata_2024-10.parquet already exists."
     ]
    }
   ],
   "source": [
    "rep_output = df.write.parquet(f\"rep/rep-{file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17738de7-0447-477e-908a-16fa673cd409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62M\tyellow_tripdata_2024-10.parquet\n"
     ]
    }
   ],
   "source": [
    "!du -h yellow_tripdata_2024-10.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cc02f3a-47e7-473f-ad0f-696361410fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98M\trep/rep-yellow_tripdata_2024-10.parquet\n"
     ]
    }
   ],
   "source": [
    "!du -h rep/rep-yellow_tripdata_2024-10.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87b7c2a5-bd3e-48fb-a9d2-e45f422b58c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'tpep_pickup_datetime',\n",
       " 'tpep_dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'RatecodeID',\n",
       " 'store_and_fwd_flag',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'congestion_surcharge',\n",
       " 'Airport_fee']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e401bdee-ff33-4826-9537-4cc0ead8b5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', IntegerType(), True), StructField('tpep_pickup_datetime', TimestampType(), True), StructField('tpep_dropoff_datetime', TimestampType(), True), StructField('passenger_count', LongType(), True), StructField('trip_distance', DoubleType(), True), StructField('RatecodeID', LongType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('PULocationID', IntegerType(), True), StructField('DOLocationID', IntegerType(), True), StructField('payment_type', LongType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('Airport_fee', DoubleType(), True)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ffcae55-6468-4f3d-89b9-3f04af70941d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|tpep_pickup_datetime|\n",
      "+--------------------+\n",
      "| 2024-10-01 22:46:41|\n",
      "| 2024-10-09 22:11:58|\n",
      "| 2024-10-03 08:41:40|\n",
      "| 2024-10-09 13:56:51|\n",
      "| 2024-10-09 10:36:09|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('tpep_pickup_datetime') \\\n",
    "  .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff13708d-21aa-45af-86e4-dfbf20503626",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"yellow_trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b91a9bdf-0bd7-43eb-97be-4eed3fb7674f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       2| 2024-10-15 20:03:15|  2024-10-15 20:21:05|           null|         3.49|      null|              null|         162|         263|           0|      18.66|  0.0|    0.5|       0.0|         0.0|                  1.0|       22.66|                null|       null|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''select *\n",
    "             from yellow_trips \n",
    "             where CAST(tpep_pickup_datetime AS DATE) = '2024-10-15'\n",
    "             and payment_type <= 0\n",
    "             ''')\\\n",
    "      .show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9ae6e73-c09d-4f64-a711-1610afade16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''select *\n",
    "             from yellow_trips \n",
    "             where CAST(tpep_pickup_datetime AS DATE) = '2024-10-15'\n",
    "             and RatecodeID <= 0\n",
    "             ''')\\\n",
    "      .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9977a9df-e81b-4a64-9305-ad2e01c76b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 121:==============>                                          (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''select *\n",
    "             from yellow_trips \n",
    "             where CAST(tpep_pickup_datetime AS DATE) = '2024-10-15'\n",
    "             and store_and_fwd_flag not in ('Y', 'N')\n",
    "             ''')\\\n",
    "      .show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9beac455-41fc-4ee7-82b6-004b4cd28546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+\n",
      "|total_amount|passenger_count|\n",
      "+------------+---------------+\n",
      "+------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''select total_amount, passenger_count\n",
    "             from yellow_trips \n",
    "             where CAST(tpep_pickup_datetime AS DATE) = '2024-10-15'\n",
    "             and fare_amount < 0\n",
    "             and payment_type in (1, 2, 3, 4)\n",
    "             and passenger_count = 0\n",
    "             ''')\\\n",
    "      .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ee4ff44-ed8b-4446-ad47-fdac897d9a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|trip_distance|\n",
      "+-------------+\n",
      "|          0.0|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('''select distinct trip_distance\n",
    "             from yellow_trips\n",
    "             where CAST(tpep_pickup_datetime AS DATE) = '2024-10-15'\n",
    "             and trip_distance <=0\n",
    "             ''')\\\n",
    "      .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d3a9157-f231-4842-aa46-2a38bc071256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  128893|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''select COUNT(1)\n",
    "             from yellow_trips\n",
    "             where CAST(tpep_pickup_datetime AS DATE) = '2024-10-15'\n",
    "             and tpep_pickup_datetime <= tpep_dropoff_datetime\n",
    "             ''')\\\n",
    "      .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc3cf8c1-aa3f-4db3-859e-c116b1166b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  115133|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('''select COUNT(1)\n",
    "             from yellow_trips \n",
    "             where CAST(tpep_pickup_datetime AS DATE) = '2024-10-15'\n",
    "             and payment_type != 0\n",
    "             ''')\\\n",
    "      .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d70e0035-ff39-4b64-a7e8-de37c77b8a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  128893|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('''select COUNT(1)\n",
    "             from yellow_trips \n",
    "             where CAST(tpep_pickup_datetime AS DATE) = '2024-10-15'\n",
    "             ''')\\\n",
    "      .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e358a96c-64bd-4020-847b-a8d9f5cbe7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''select COUNT(PULocationID)\n",
    "             from yellow_trips \n",
    "             where CAST(tpep_pickup_datetime AS DATE) = '2024-10-15'\n",
    "             and PULocationID is NULL\n",
    "             ''')\\\n",
    "      .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb3da4a3-5ff4-437c-bb2b-74f7c0f6e339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  126164|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''select COUNT(1)\n",
    "             from yellow_trips \n",
    "             where CAST(tpep_pickup_datetime AS DATE) = '2024-10-15'\n",
    "             and CAST(tpep_dropoff_datetime AS DATE) >= '2024-10-15'\n",
    "             and fare_amount > 0\n",
    "             ''') \\\n",
    "      .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb254ca5-da9b-4fa5-ba62-5f2783309789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bd8a4d4-5b68-42fd-a3b8-1937351a3c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = pd.read_parquet(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39512258-3df5-4c04-a5df-0899668c6650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                          int32\n",
       "tpep_pickup_datetime     datetime64[us]\n",
       "tpep_dropoff_datetime    datetime64[us]\n",
       "passenger_count                 float64\n",
       "trip_distance                   float64\n",
       "RatecodeID                      float64\n",
       "store_and_fwd_flag               object\n",
       "PULocationID                      int32\n",
       "DOLocationID                      int32\n",
       "payment_type                      int64\n",
       "fare_amount                     float64\n",
       "extra                           float64\n",
       "mta_tax                         float64\n",
       "tip_amount                      float64\n",
       "tolls_amount                    float64\n",
       "improvement_surcharge           float64\n",
       "total_amount                    float64\n",
       "congestion_surcharge            float64\n",
       "Airport_fee                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97bfd844-1baa-4ab3-8147-3d5837d0e31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df_oct_15 = pandas_df[(pandas_df[\"tpep_pickup_datetime\"] >= \"2024-10-15 00:00:00\") & (pandas_df[\"tpep_pickup_datetime\"] <= \"2024-10-15 23:59:59\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c4fa83d-6f3b-40d7-8574-c8b034f7e7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128893"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pandas_df_oct_15.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8e9b40b5-a58a-4ed8-9461-c9d52ec9a9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 194:==========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+--------+\n",
      "|tpep_pickup_datetime|tpep_dropoff_datetime|duration|\n",
      "+--------------------+---------------------+--------+\n",
      "+--------------------+---------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''select tpep_pickup_datetime, tpep_dropoff_datetime, TIMESTAMPDIFF(MINUTE,tpep_pickup_datetime, tpep_dropoff_datetime) as duration\n",
    "             from yellow_trips \n",
    "             where CAST(tpep_pickup_datetime AS DATE) = '2024-10-15'\n",
    "             and CAST(tpep_dropoff_datetime AS DATE) >= '2024-10-15'\n",
    "             and fare_amount > 0\n",
    "             and trip_distance > 0\n",
    "             and TIMESTAMPDIFF(MINUTE,tpep_pickup_datetime, tpep_dropoff_datetime) < 0\n",
    "             ''') \\\n",
    "      .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7ca05eb-8301-47dd-ad5f-73127873cb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|payment_type|\n",
      "+------------+\n",
      "|           0|\n",
      "|           1|\n",
      "|           3|\n",
      "|           2|\n",
      "|           4|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''select distinct payment_type\n",
    "             from yellow_trips \n",
    "             where CAST(tpep_pickup_datetime AS DATE) = '2024-10-15'\n",
    "             ''')\\\n",
    "      .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24f30be1-21f9-457f-98f0-751f0f090c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------+\n",
      "|max(timestampdiff(HOUR, tpep_pickup_datetime, tpep_dropoff_datetime))|\n",
      "+---------------------------------------------------------------------+\n",
      "|                                                                  162|\n",
      "+---------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('''select MAX(TIMESTAMPDIFF(HOUR,tpep_pickup_datetime, tpep_dropoff_datetime))\n",
    "             from yellow_trips\n",
    "             where CAST(tpep_pickup_datetime AS DATE) >= '2024-10-01' and\n",
    "             CAST(tpep_pickup_datetime AS DATE) <= '2024-10-31'\n",
    "             ''')\\\n",
    "      .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d85894b4-f5d4-4e00-8df1-8898f636ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 5\n",
    "#Since i'm not running pyspark on standalone mode, the jobs UI runs on port 4040 by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f673fc9-12ae-43df-bb25-470fac04ec9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-06 13:35:47--  https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 13.226.36.130, 13.226.36.196, 13.226.36.73, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|13.226.36.130|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12331 (12K) [text/csv]\n",
      "Saving to: ‘taxi_zone_lookup.csv’\n",
      "\n",
      "taxi_zone_lookup.cs 100%[===================>]  12.04K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-03-06 13:35:47 (126 MB/s) - ‘taxi_zone_lookup.csv’ saved [12331/12331]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f714f16f-71ac-4b40-a9ea-a87137491da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_file_path = \"taxi_zone_lookup.csv\"\n",
    "df_lookup = spark.read.option(\"header\",True) \\\n",
    "            .csv(lookup_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2c82204-e18c-439a-be1e-6496fdc52365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LocationID', 'Borough', 'Zone', 'service_zone']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lookup.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "847e8411-7ab6-4cdb-9ebe-35c1af02b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lookup.createOrReplaceTempView(\"zones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd7d2340-6438-48c8-b981-78515ba6edfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 174:==============>                                          (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+\n",
      "|                Zone|PULocationID|trips|\n",
      "+--------------------+------------+-----+\n",
      "|Governor's Island...|         105|    1|\n",
      "|       Rikers Island|         199|    2|\n",
      "|       Arden Heights|           5|    2|\n",
      "|         Jamaica Bay|           2|    3|\n",
      "| Green-Wood Cemetery|         111|    3|\n",
      "|Charleston/Totten...|          44|    4|\n",
      "|       West Brighton|         245|    4|\n",
      "|       Port Richmond|         187|    4|\n",
      "|Eltingville/Annad...|          84|    4|\n",
      "|   Rossville/Woodrow|         204|    4|\n",
      "|        Crotona Park|          59|    6|\n",
      "|         Great Kills|         109|    6|\n",
      "|Heartland Village...|         118|    7|\n",
      "|     Mariners Harbor|         156|    7|\n",
      "|Saint George/New ...|         206|    9|\n",
      "|             Oakwood|         176|    9|\n",
      "|       Broad Channel|          30|   10|\n",
      "|New Dorp/Midland ...|         172|   10|\n",
      "|     Pelham Bay Park|         184|   12|\n",
      "|         Westerleigh|         251|   12|\n",
      "+--------------------+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('''select zones.Zone,\n",
    "                    yellow_trips.PULocationID,\n",
    "                    COUNT(yellow_trips.PULocationID) as trips\n",
    "             from yellow_trips, zones\n",
    "             where yellow_trips.PULocationID = zones.LocationID\n",
    "             group by zones.Zone, yellow_trips.PULocationID\n",
    "             order by trips ASC\n",
    "          ''') \\\n",
    "          .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "48aadfa3-c79a-4660-982f-4bd7866f1eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       1|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''select count(1)\n",
    "             from yellow_trips\n",
    "             where PULocationID = 105\n",
    "          ''') \\\n",
    "          .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39venv",
   "language": "python",
   "name": "py39venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
